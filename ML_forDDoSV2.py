import pandas as pd
import numpy as np
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder

# ğŸ“Œ **à¹‚à¸«à¸¥à¸” Dataset**
dataset_path = "./dataset/Combined_Traffic_Dataset_With_Normal.csv"  # à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹€à¸›à¹‡à¸™ path à¸‚à¸­à¸‡à¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸‡à¸²à¸™
df = pd.read_csv(dataset_path, low_memory=False, dtype=str)  # à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸›à¹‡à¸™ string à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”

# ğŸ“Œ **à¹€à¸¥à¸·à¸­à¸ Features à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰**
selected_features = [
    "Application", "Repeat Count", "IP Protocol", "Bytes", "Bytes Sent", "Bytes Received",
    "Packets", "Elapsed Time (sec)", "Packets Sent", "Packets Received", "Session End Reason",
    "Risk of app", "Characteristic of app", "Packets per second", "Bytes per second", "Average packet size"
]

# ğŸ“Œ **à¹à¸¢à¸ Features à¹€à¸›à¹‡à¸™ Numeric à¹à¸¥à¸° String**
string_features = ["Application", "Session End Reason", "Characteristic of app"]
numeric_features = [col for col in selected_features if col not in string_features]

# ğŸ“Œ **à¹à¸›à¸¥à¸‡ String Features à¹€à¸›à¹‡à¸™à¸•à¸±à¸§à¹€à¸¥à¸‚à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰ Label Encoding**
df_encoded = df[selected_features].copy()
label_encoders = {}
for col in string_features:
    le = LabelEncoder()
    df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))
    label_encoders[col] = le

# ğŸ“Œ **à¹à¸›à¸¥à¸‡à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸•à¸±à¸§à¹€à¸¥à¸‚à¸ˆà¸²à¸ string â†’ numeric (à¸ˆà¸±à¸”à¸à¸²à¸£ Mixed Data Type)**
for col in numeric_features:
    df_encoded[col] = pd.to_numeric(df_encoded[col], errors='coerce')  # à¹à¸›à¸¥à¸‡à¸„à¹ˆà¸²à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™ NaN

# ğŸ“Œ **à¹à¸—à¸™à¸„à¹ˆà¸²à¸«à¸²à¸¢à¹„à¸›**
for col in numeric_features:
    df_encoded[col].fillna(df_encoded[col].median(), inplace=True)  # à¹ƒà¸Šà¹‰à¸„à¹ˆà¸²à¸à¸¥à¸²à¸‡à¹€à¸•à¸´à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸«à¸²à¸¢à¹„à¸›

# ğŸ“Œ **à¹à¸—à¸™à¸„à¹ˆà¸² Label à¸•à¸²à¸¡à¸—à¸µà¹ˆà¸à¸³à¸«à¸™à¸”**
label_mapping = {"Normal": 0, "DoS": 1, "DDoS": 2, "Slowloris": 3}
df_encoded["Label"] = df["Label"].map(label_mapping)

# ğŸ“Œ **à¹à¸¢à¸ Features à¹à¸¥à¸° Target**
X = df_encoded.drop(columns=["Label"])
y = df_encoded["Label"]

# ğŸ“Œ **à¹à¸šà¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸›à¹‡à¸™ Train/Test (80:20)**
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# ğŸ“Œ **à¸à¸³à¸«à¸™à¸”à¸à¸²à¸£à¸²à¸¡à¸´à¹€à¸•à¸­à¸£à¹Œà¸ªà¸³à¸«à¸£à¸±à¸š GridSearchCV**
param_grid = {
    'n_estimators': [50, 100, 200],  # à¸ˆà¸³à¸™à¸§à¸™à¸•à¹‰à¸™à¹„à¸¡à¹‰
    'max_depth': [None, 10, 20, 30],  # à¸„à¸§à¸²à¸¡à¸¥à¸¶à¸à¸‚à¸­à¸‡à¸•à¹‰à¸™à¹„à¸¡à¹‰
    'min_samples_split': [2, 5, 10],  # à¸ˆà¸³à¸™à¸§à¸™à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸‚à¸±à¹‰à¸™à¸•à¹ˆà¸³à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸¡à¸µà¹ƒà¸™à¸à¸²à¸£à¹à¸šà¹ˆà¸‡ node
    'min_samples_leaf': [1, 2, 4]  # à¸ˆà¸³à¸™à¸§à¸™à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸‚à¸±à¹‰à¸™à¸•à¹ˆà¸³à¹ƒà¸™ leaf node
}

# ğŸ“Œ **à¸ªà¸£à¹‰à¸²à¸‡ GridSearchCV**
grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42), 
                           param_grid=param_grid, 
                           cv=3,  # Cross-validation 3 folds
                           n_jobs=-1,  # à¹ƒà¸Šà¹‰à¸—à¸¸à¸ CPU core
                           verbose=2)  # à¹à¸ªà¸”à¸‡à¸œà¸¥à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™

# ğŸ“Œ **Train Grid Search**
grid_search.fit(X_train, y_train)

# ğŸ“Œ **à¹à¸ªà¸”à¸‡à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸—à¸µà¹ˆà¸”à¸µà¸—à¸µà¹ˆà¸ªà¸¸à¸”**
best_params = grid_search.best_params_
best_score = grid_search.best_score_

print(f"ğŸ” Best Parameters: {best_params}")
print(f"âœ… Best Model Score: {best_score:.4f}")

# ğŸ“Œ **Train à¹‚à¸¡à¹€à¸”à¸¥à¸”à¹‰à¸§à¸¢à¸à¸²à¸£à¸²à¸¡à¸´à¹€à¸•à¸­à¸£à¹Œà¸—à¸µà¹ˆà¸”à¸µà¸—à¸µà¹ˆà¸ªà¸¸à¸”**
best_model = RandomForestClassifier(**best_params, random_state=42)
best_model.fit(X_train, y_train)

# ğŸ“Œ **à¸—à¸³à¸™à¸²à¸¢à¸œà¸¥à¸šà¸™à¸Šà¸¸à¸”à¸—à¸”à¸ªà¸­à¸š**
y_pred = best_model.predict(X_test)

# ğŸ“Œ **à¸›à¸£à¸°à¹€à¸¡à¸´à¸™à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ**
accuracy = accuracy_score(y_test, y_pred)
print(f"ğŸ¯ Model Accuracy (Best Tuned): {accuracy:.4f}")
print("Classification Report:\n", classification_report(y_test, y_pred))

# ğŸ“Œ **à¹à¸ªà¸”à¸‡ Confusion Matrix**
plt.figure(figsize=(6, 4))
conf_matrix = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=label_mapping.keys(), yticklabels=label_mapping.keys())
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix (Best Tuned Model)")
plt.show()

# ğŸ“Œ **à¸šà¸±à¸™à¸—à¸¶à¸à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸µà¹ˆà¸”à¸µà¸—à¸µà¹ˆà¸ªà¸¸à¸”**
joblib.dump(best_model, "RandomForest_Traffic_ModelV1.pkl")
print("âœ… Best Model saved as Best_RandomForest_Traffic_Model.pkl")
